# 关于接下来的若干探索方向
## 针对注意力可视化的更多探索
- 类似论文，对easy，medium,hard类型的点进行可视化,特别是对同一张图中重复性比较多的点进行可视化,观察crossAttention和selfAttention的情况.
	- [Superglue中的Attention层的可视化](../科研/毕业设计/Superglue中的Attention层的可视化.md)
## 针对分类划分图节点进行图卷积的尝试
- [[coco2017-test数据集模型评估结果]]
	- **对照**:[20epoh-原始网络-完全图](20epoh-原始网络-完全图.md)
	- [[多个模型对比效果的实现]]
- ? 利用输入时的向量只划分一次图,还是在每一个attention层都根据更新得的新向量重新划分
	- 目前做的是后者
- **把全连接图分组**-两种划分图的方式
	- 按照K近邻方式划分为图G1,G2
		- [K近邻划分图的pytorch实现](K近邻划分图的pytorch实现.md)
		- [20230118-20epoh-单纯拼接k近邻-慢且效果差](20230118-20epoh-单纯拼接k近邻-慢且效果差.md)
			- **慢的原因**
				- 是否是求K近邻消耗时间-==是==
				-  [[关于是否是求K近邻消耗时间-20230118-20epoh]]
				- [[根据距离矩阵转为只连接K近邻的邻接矩阵]]
		- [[更新注意力时,每个节点只利用其2近邻更新信息,20epoch]]
		- [[20230130-20-单纯8+16近邻-prec,recall都低]]
		- [[8近邻更新信息 cat 全连接图更新信息]]
		- [[30epoh-原始网络-完全图]]
		- [[20230130-30-8+16+32+all-不同K通过不同网络]]
		- **两种方式**
			- G1属于G2
			- G1与G2不相交
		- ![](attachments/2023-01-12%202023-01-12%2022.02.34.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-12%202023-01-12%2022.02.34.excalidraw.md), and the [dark exported image](attachments/2023-01-12%202023-01-12%2022.02.34.excalidraw.dark.svg)%%
	- 按照均分方式划分图(**互斥的集合**)
		- ![](attachments/2023-01-12%202023-01-12%2022.07.09.excalidraw.svg)
		- %%[🖋 Edit in Excalidraw](attachments/2023-01-12%202023-01-12%2022.07.09.excalidraw.md), and the [dark exported image](attachments/2023-01-12%202023-01-12%2022.07.09.excalidraw.dark.svg)%%
	- 其他:最少生成树等
- ? **分组后消息传递的方式**
	- 问题
		- Superglue是全连接图
			- message = self.attn(x, source, source)
	- **方法1**:根据邻接矩阵将无连接边的权重置为零
		- 如[图注意力网络GAT](../科研/毕业设计/图注意力网络GAT.md)的实现
		- **缺点**:即便是稀疏图,依旧是O(n2)的计算复杂度
## 对在**不同尺度的**图上卷积出的结果进行正交约束
- [注意力导向的GCN用于关系提取任务 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/139350840)
- 目的在于想要学到重合度较低的描述向量
- 在图G1上更新出(N(G1),256)维新描述向量$f_{1}$
- 在图G2上更新出(N(G2),256)维新描述向量$f_{2}$
- **加正交约束的方式**
	- **损失函数**
		- 在损失函数出设置$f_{1}与f_{2}$的正交约束
	- 选取f2和g1(**两个相互正交的向量**)
	- ![](attachments/2023-01-12%202023-01-12%2022.17.37.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-12%202023-01-12%2022.17.37.excalidraw.md), and the [dark exported image](attachments/2023-01-12%202023-01-12%2022.17.37.excalidraw.dark.svg)%%
- 将两个正交向量f2,g1进行cat得到新的(N(G),512)维新描述向量
	- [[计算正交向量的pytorch实现-两两正交]]
- 放入MLP中降维为(N(G),256)
## 关于利用Attention更新时wf的f选取
- 在不断更新注意力系数的同时,也对V不断进行更新,由于前期注意力矩阵分布并不靠谱,后期V可能被噪声过于冲淡.
- **尝试**
	- 开始的几轮不进行全连接图的attention
	- V值不采用新值,而是采用原始值/多轮更新一次
- ![](attachments/Pasted%20image%2020230109173744.png)
- ![](attachments/2023-01-12%202023-01-12%2021.56.33.excalidraw.svg)
%%[🖋 Edit in Excalidraw](attachments/2023-01-12%202023-01-12%2021.56.33.excalidraw.md), and the [dark exported image](attachments/2023-01-12%202023-01-12%2021.56.33.excalidraw.dark.svg)%%
## 在注意力系数与图预构建方向
- 对于下图的情形
	- x1,x2的注意力系数永远设为0？
	- 或者传入的图中直接不包含与x1与x2的连线？
	- 或者根据K值，对图像特征点 预处理出一个邻接矩阵，传入网络？
	- 
	- ![](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.md), and the [dark exported image](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.dark.svg)%%
	- ![](attachments/2023-01-11%202023-01-12%2018.28.58.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-11%202023-01-12%2018.28.58.excalidraw.md), and the [dark exported image](attachments/2023-01-11%202023-01-12%2018.28.58.excalidraw.dark.svg)%%
	- 
- 更进一步，选取k时，不仅要关注两点间的距离，还希望每次增加k都能带来更多的信息
	- 设置距离系数,正交系数？
	- ![](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.md), and the [dark exported image](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.dark.svg)%%
