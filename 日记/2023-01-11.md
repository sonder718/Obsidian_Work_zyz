##### 1月6日以来的探索
- 将官方代码的前向推理过程逐步断点运行
- 尝试使用github上star较多的一训练代码
	- https://github.com/HeatherJiaZG/SuperGlue-pytorch
	- 在云服务器RTX 3080 Ti上抽取1/16的Coco2017数据集初步训练模型
	- 模型与官方评估代码不兼容，且未附有代码
	- 多日魔改未果，bug不断
- 遂尝试采用另一训练代码
	- [gouthamvgk/SuperGlue_training: This repository contains the training code for SuperGlue. Uses COCO dataset by generating random homographies. (github.com)](https://github.com/gouthamvgk/SuperGlue_training)
	- star虽少，但结构非常清晰，且没有魔改官方网络结构
	- 训练集为抽取1/16的Coco2017数据集，进行随机单应变换和光度失真
	- 在云服务器RTX 3080 Ti上初步尝试训练模型，为降低花销，只为测试可用性，进行了3个epoch
		- 过程中loss逐步收敛，可以预见继续训练能取得良好效果
		- ![](attachments/Pasted%20image%2020230110222438.png)
	- 稍作调整后，至此，对superglue的训练评估与测试代码的准备工作已经完成
- 为进一步理解superglue中的注意力机制，效仿论文将推理过程中不同层下的注意力矩阵可视化
	- 将特征点i的高于平均值的注意力值可视化
	- [cross attention可视化](../cross%20attention可视化.canvas)
	- ![](attachments/Pasted%20image%2020230111154722.png)
	- ![](attachments/Pasted%20image%2020230111154927.png)
	- [self attention可视化](../self%20attention可视化.canvas)
	- ![](attachments/Pasted%20image%2020230111154552.png)
	- ![](attachments/Pasted%20image%2020230111154627.png)
- **关于下面要做工作的理解，不确定是否理解正确了？**
	- 对于下图的情形
		- x1,x2的注意力系数永远设为0？
		- 或者传入的图中直接不包含与x1与x2的连线？
		- 或者根据K值，对图像特征点 预处理出一个邻接矩阵，传入网络？
		- ![](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.md), and the [dark exported image](attachments/2023-01-11%202023-01-11%2015.50.45.excalidraw.dark.svg)%%
	- 更进一步，选取k时，不仅要关注两点间的距离，还希望每次增加k都能带来更多的信息
		- 设置距离系数,正交系数
		- ![](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.svg)%%[🖋 Edit in Excalidraw](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.md), and the [dark exported image](attachments/2023-01-11%202023-01-11%2016.28.15.excalidraw.dark.svg)%%