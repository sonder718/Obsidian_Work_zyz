# 求解问题概述

为了评估算法的全局搜索能力，本文选取了10个基准测试函数来测试算法求解连续优化问题的综合性能。

10个基准测试函数包括3个单峰函数优化问题和7个多峰函数优化问题

## 实验基准测试函数

10个基准测试函数的函数名称，函数表达式，搜索空间，全局最优位置，全局最优值如下表所示

| 函数名称                  | 函数类型 | 维度 | 搜索空间                     | 全局最优位置($X^{*}$) | 全局最优值($f(X^{*})$) |
| ------------------------- | -------- | ---- | ---------------------------- | --------------------- | ---------------------- |
| $f_{1}(X)$:ACKLEY         | 多峰函数 | d    | $[-40,40]^{D}$               | ${[0]}^{D}$           | 0.0                    |
| $f_{2}(X)$:SPHERE         | 单峰函数 | d    | $[-100,100]^{D}$             | ${[0]}^{D}$           | 0.0                    |
| $f_{3}(X)$:SUM SQUARES    | 单峰函数 | d    | $[-10,10]^{D}$               | ${[0]}^{D}$           | 0.0                    |
| $f_{4}(X)$:BOHACHEVSKY    | 单峰函数 | 2    | $[-100,100]^{D}$             | ${[0]}^{D}$           | 0.0                    |
| $f_{5}(X)$:BUKIN FUNCTION | 多峰函数 | 2    | x1 ∈ [-15, -5], x2 ∈ [-3, 3] | (-10,1)               | 0.0                    |
| $f_{6}(X)$:DROP-WAVE      | 多峰函数 | 2    | xi ∈ [-5.12, 5.12]           | (0,0)                 | -1                     |
| $f_{7}(X)$:GRIEWANK       | 多峰函数 | d    | $[-600,600]^{D}$             | ${[0]}^{D}$           | 0.0                    |
| $f_{8}(X)$:Shubert N. 4   | 多峰函数 | 2    | $[-10,10]^{D}$               |                       | −25.740858             |
| $f_{9}(X)$:SCHAFFER       | 多峰函数 | 2    | [-100, 100]                  | (0,0)                 | 0.0                    |
| $f_{10}(X)$:SCHWEFEL      | 多峰函数 | d    | $[-100,100]^{D}$             | ${[420.9687]}^{D}$    | 0.0                    |



各函数表达式与函数图像如下

1. ACKLEY：

$$
f(\mathbf{x})=-a \exp \left(-b \sqrt{\frac{1}{d} \sum_{i=1}^{d} x_{i}^{2}}\right)-\exp \left(\frac{1}{d} \sum_{i=1}^{d} \cos \left(c x_{i}\right)\right)+a+\exp
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547067300221.png" alt="output" style="zoom:36%;" />

2. SPHERE：

$$
f(\mathbf{x})= \sum_{i=1}^{d} x_{i}^{2}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547667418351.png" alt="output" style="zoom:36%;" />

3. SUM SQUARES:

$$
f(\mathbf{x})= \sum_{i=1}^{d} ix_{i}^{2}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547778407826.png" alt="output" style="zoom:36%;" />

4. BOHACHEVSKY:

$$
\begin{gathered}
f(\mathbf{x})=x_{1}^{2}+2 x_{2}^{2}-0.3 \cos \left(3 \pi x_{1}\right)-0.4 \cos \left(4 \pi x_{2}\right)+0.7
\end{gathered}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547781949377.png" alt="output" style="zoom:36%;" />

5. BUKIN FUNCTION N. 6

$$
f(\mathbf{x})=100 \sqrt{\left|x_{2}-0.01 x_{1}^{2}\right|}+0.01\left|x_{1}+10\right|
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547784117838.png" alt="output" style="zoom:36%;" />

6. DROP-WAVE:

$$
f(\mathbf{x})=-\frac{1+\cos \left(12 \sqrt{x_{1}^{2}+x_{2}^{2}}\right)}{0.5\left(x_{1}^{2}+x_{2}^{2}\right)+2}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165477872311110.png" alt="output" style="zoom:36%;" />

6. GRAMACY & LEE (2012)

$$
f(x)=\frac{\sin (10 \pi x)}{2 x}+(x-1)^{4}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165477922059711.png" alt="output" style="zoom:36%;" />

7. GRIEWANK :

$$
f(\mathbf{x})=\sum_{i=1}^{d} \frac{x_{i}^{2}}{4000}-\prod_{i=1}^{d} \cos \left(\frac{x_{i}}{\sqrt{i}}\right)+1
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547936112921.png" alt="output" style="zoom:36%;" />

8. ACKLEY N.3 FUNCTION

$$
f(x)==\sum_{i=1}^{n} \sum_{j=1}^{5} j \cos \left((j+1) x_{i}+j\right)
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547936407332.png" alt="output" style="zoom:36%;" />

9. SCHAFFER 

$$
f(\mathbf{x})=0.5+\frac{\sin ^{2}\left(x_{1}^{2}-x_{2}^{2}\right)-0.5}{\left[1+0.001\left(x_{1}^{2}+x_{2}^{2}\right)\right]^{2}}
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547941493353.png" alt="output" style="zoom:36%;" />

10. SCHWEFEL 

$$
f(\mathbf{x})=418.9829 d-\sum_{i=1}^{d} x_{i} \sin \left(\sqrt{\left|x_{i}\right|}\right)
$$

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547944194444.png" alt="output" style="zoom:36%;" />



# 优化方法概述

## PSO

### 粒子群算法简介

粒子群优化算法(PSO：Particle swarm optimization) 是一种进化计算技术（evolutionary computation）。源于对鸟群捕食的行为研究。粒子群优化算法的基本思想：是通过群体中个体之间的协作和信息共享来寻找最优解．

其基本思想如下:粒子群算法通过设计一种无质量的粒子来模拟鸟群中的鸟，粒子仅具有两个属性：速度和位置，速度代表移动的快慢，位置代表移动的方向。每个粒子在搜索空间中单独的搜寻最优解，并将其记为当前个体极值，并将个体极值与整个粒子群里的其他粒子共享，找到最优的那个个体极值作为整个粒子群的当前全局最优解，粒子群中的所有粒子根据自己找到的当前个体极值和整个粒子群共享的当前全局最优解来调整自己的速度和位置。

### 粒子群算法流程

粒子群算法流程如下:

```mermaid
graph TD;
%% 求解约束下的函数优化问题,所有粒子在一个n维空间搜索,粒子:x,y,v,pbest 种群:gbest
%% 通过群体的协作使群体达到最优目的
A[初始化目标函数与参数] %%参数包括惯性常数w,个体认知常数c1,社会经验常数c2
%% 研究者发现最初版本的PSO 算法在解决某些问题时,由于搜索行为太偏全局,从而导致算法的收敛速度过慢。为了解决这个问题, Shi和Eberhart7]提出了具有惯性权重的PSO算法,即在公式21中加入了惯性权重w:

A-->B[随机初始化粒子的位置与速度] %% 位置在定义域上下界内,速度在定义域长度内
B-->C[粒子适应值计算]
C-->M[更新全局最优解与局部最优解]-->D{是否达到停止条件}
D--未达到-->E[更新粒子速度] %%根据惯性,个体认知,社会认知
%% 惯性是保留部分此前的速度
%% 个体认知是参数*(个体最优-当前位置)即往个人最好点走,并带有一定的随机性
%% 社会认知即往全局最优点走
E-->F[根据速度更新粒子位置]-->C
D--达到-->输出最优结果

```

#### 粒子速度更新

$\mathbf{v}_{i}(t) \rightarrow \mathbf{v}_{i}(t+1)$

$\mathbf{v}_{i}(t+1)=$ Inertial $+$ Cognitive $+$ Social
$\mathbf{v}_{i}(t+1)=w \times \mathbf{v}_{i}(t)+$$c_{1} \times$ rndreal $_{1}() \times\left(\right.$ PBest $\left._{i}-\mathbf{x}_{i}(t)\right)+$$c_{2} \times$ rndreal $_{2}() \times\left(\right.$ GBest $\left.-\mathbf{x}_{i}(t)\right)$

- $w$ 是惯性常数
- $c_{1}$ 是个体认知常数
- $c_{2}$ 是社会经验常数
- rndreal $_{1}()$, rndreal $_{2}()$ 是 $(0,1)$ 之间的随机数

#### 粒子位置更新

粒子位置更新： $\mathbf{x}_{i}(t) \rightarrow \mathbf{x}_{i}(t+1)$
$$
\mathbf{x}_{i}(t+1)=\mathbf{x}_{i}(t)+\mathbf{v}_{i}(t+1)
$$

## DE

### 差分进化算法简介

差分进化算法(Differential Evolution Algorithm，DE)是一种高效的全局优化算法。它也是基于群体的启发式搜索算法，群中的每个个体对应一个解向量。差分进化算法的进化流程包括变异、杂交和选择操作,它是通过**群体内个体间的合作与竞争**而产生的智能优化算法，字面意思即可看出它有别于遗传算法的自由组合自然选择，它更侧重的是个体与个体和个体与自身间的关系，包括合作与竞争。

### 差分进化算法流程

差分进化算法流程如下

```mermaid
graph TD;
%% 求解约束下的函数优化问题
A[初始化目标函数与约束]-->B[初始化参数,种群初始化]-->D %%均匀随机初始化 
D[利用差分变异算子进行变异]-->E["交叉(离散重组)"] %% DE/rand/1
E-->F["贪婪选择((实现约束条件利用罚函数))"]-->G["记录最优解"] 	
G--未到最大迭代次数-->D
G-->完成迭代-->H[记录全局最优解]




```

#### 初始化

需要初始化第 0 代的种群个体, 假定每个种群个体 $i$ 的每个自变量参数j的值都服从上下限之间的均匀分布, 即
$$
\begin{gathered}
X_{i j, 0}=\operatorname{rand}[0,1] *\left(X_{j}^{(U)}-X_{j}^{(L)}\right)+X_{j}^{(L)} \\
\text { 其中 } i=1,2, \ldots, N P ; j=1,2, \ldots, D
\end{gathered}
$$

#### 变异

变异公式为
$$
v_{i, G+1}=X_{r 1, G}+F *\left(X_{r 2, G}-X_{r 3, G}\right)
$$
$v_{i, G+1}$ 为当前为第 $i$ 个的个体在进入变异成下一代后的个体, $F$ 为缩放因子, 一般取值范围为 $[0,2]$, 用于控制差向量值的放大

#### 交叉

设在 $G_{0}$ 代的个体 $\mathrm{i}$ 在发生变异后变异成为了 $u_{i, G_{0}+1}$, 则此时的交叉操作体现在
$$
u_{i j, G_{0}+1}=\left\{\begin{array}{l}
v_{i j, G_{0}+1}, \text { 当 } \operatorname{randb}(j)<=C R \text { 或 } j=r n b r(i) \\
X_{i j, G_{0}}, \text { 当 } \operatorname{randb}(j)>C R \text { 且 } j !=\operatorname{rnbr}(i)
\end{array}\right.
$$
其中 $\operatorname{randb}(j)$ 为 $[0,1]$ 随机数序列中的第 $\mathrm{j}$ 个估计值, $\operatorname{rnbr}(\mathrm{i})$ 为表示第 $\mathrm{i}$ 个 个体产生的在 $[1, D]$ 范围上的随机数, $\mathrm{CR}$ 为交叉概率

## GA



### 遗传算法简介

遗传算法（Genetic Algorithm，简称GA）是一种**随机全局搜索优化**方法，它模拟了自然选择和遗传中发生的**复制**、**交叉**和**变异**等现象，从任一初始种群出发，通过随机选择、交叉和变异操作，产生一群更适合环境的个体，使群体进化到搜索空间中越来越好的区域，这样一代一代不断繁衍进化，最后收敛到一群最适应环境的个体，从而求得问题的优质解。

### 遗传算法流程

算法流程如下:

```mermaid
graph TD;
	设置种群大小,编码染色体,定义适应值函数-->A %%定义问题参数空间到编码空间的映射,本问题中将十进制转化为为二进制,求解的是整数优化问题,染色体初始长度由定义域决定
    A["初始化种群(定义域内随机初始化)"]-->B["解码,获取当前适应度"];%%目标函数的一种形式
    B-->C[轮盘赌选择父母] %%轮盘赌  好的个体更容易被选
    C--满足交叉概率-->D[单点杂交] %%
    D--满足变异概率-->F[单点变异] %%随机确定一个变异点,0-1互换
    F-->自然选择-->G[新个体加入新的种群]
    G--不满足种群大小-->C
    G--满足种群大小要求-->B
    B--迭代次数满足要求-->H[获取最大适应度]-->得到问题的解
    
 
    
    
 
```

# 实验结果

## 测试指标

在所有测试函数中，分别利用**PSO，DE，GA**设置进化代数，种群大小和其他参数，对每个函数在 2维，10维，50 维时独立运行 20 次，求解并记录**20次**的最好解，最差解，平均值，标准差,平均函数评价次数,平均运行时间。

在实际中,智能优化算法并不能总收敛到最优解,本文尝试采用达优率来反映算法的精度.

优化算法的达优率,指优化算法能够搜索到最优解的概率,通常将优化算法运行多次,用搜索到最优解的次数和总运行次数之比来估计其**达优率**$\eta$.

在此本文假设所求最优解的值与全局最优解的值**相差小于0.0001**即判定搜索到最优解.
$$
\eta=n_{0}/n
$$
仅仅考察算法的精度,并不能够全面反映一个优化算法总体性能。如果一个算法精度很高,但是它耗费的时间代价太大,那就不能说它是一个好的算法。因此,要全面地考察算法的性能,必须要考虑算法的精度和算法的运行时间两方面因素。

优化算法的**精度时间比**,是指一个优化算法的解的精度与时间的比值
$$
\mu=\eta/t
$$



## 测试结果

### PSO

#### 维度变化与参数选择

本文尝试对**2,5,10,50维**ACKLEY函数利用PSO进行求解，探索了不同维度下，设置**不同种群大小与进化代数时函数的表现**，实验结果见下表：

实验设置惯性权重w=0.8,个体最优惩罚因子c1=0.5,全局最优惩罚因子c2=0.5.

实验表明当设置进化代数为1000,种群大小为50时,面对维度为2与5维的ACKLEY函数,PSO算法性能极好,能达到100%的达优率.而同样的进化代数与种群大小,面对10维的ACKLEY函数,算法陷入了局部最优,达优率为0.

通过提升进化代数,达优率并没有提升,而精度时间比在不断下降.

当提升种群大小到300时,达优率终于到达0.6,可见面对高维函数,算法更易陷入局部最优,而提升种群大小是一种很好的防止陷入局部最优的方法.

| 函数              | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解   | 最差解   | 平均值   | 标准差   | 达优次数 | 达优率  | 精度时间比 |
| ----------------- | ---- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ------- | ---------- |
| $f_{1}(X)$:ACKLEY | 2    | 1000     | 50       | 20       | 1.43652  | 0.00000  | 0.00000  | 0.00000  | 0.00000  | 20.00000 | 1.00000 | 0.69613    |
| $f_{1}(X)$:ACKLEY | 5    | 1000     | 50       | 20       | 1.41347  | 0.00000  | 0.00000  | 0.00000  | 0.00000  | 20.00000 | 1.00000 | 0.70748    |
| $f_{1}(X)$:ACKLEY | 10   | 1000     | 50       | 20       | 1.4373   | 19.97831 | 20.02331 | 19.98888 | 0.008948 | 0        | 0       | 0          |
| $f_{1}(X)$:ACKLEY | 10   | 1000     | 100      | 20       | 2.96195  | 0.00000  | 19.99224 | 15.99026 | 7.99513  | 4.00000  | 0.20000 | 0.06752    |
| $f_{1}(X)$:ACKLEY | 10   | 2000     | 100      | 20       | 6.16081  | 0.00000  | 19.99196 | 15.98949 | 7.99475  | 4.00000  | 0.20000 | 0.03246    |
| $f_{1}(X)$:ACKLEY | 10   | 3000     | 100      | 20       | 11.23817 | 0.00000  | 19.99235 | 17.07279 | 6.94799  | 2.00000  | 0.10000 | 0.00890    |
| $f_{1}(X)$:ACKLEY | 10   | 1000     | 200      | 20       | 6.25019  | 0.00000  | 19.99106 | 15.99046 | 7.99523  | 4.00000  | 0.20000 | 0.03200    |
| $f_{1}(X)$:ACKLEY | 10   | 1000     | 300      | 20       | 10.2380  | 0.0000   | 19.9899  | 7.9949   | 9.7917   | 12.0000  | 0.6000  | 0.0586     |
| $f_{1}(X)$:ACKLEY | 50   | 1000     | 300      | 20       | 10.9235  | 19.9878  | 19.9927  | 19.9905  | 0.0013   | 0.0000   | 0.0000  | 0.0000     |

#### 维度为2的基准测试函数

| 函数 | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解   | 最差解   | 平均值   | 标准差 | 达优次数 | 达优率 | 精度时间比 |
| ---- | ---- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ------ | -------- | ------ | ---------- |
| F1   | 2    | 1000     | 100      | 20       | 2.96     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.70       |
| F2   | 2    | 1000     | 100      | 20.00    | 0.87     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 1.14       |
| F3   | 2    | 1000     | 100      | 20.00    | 0.30     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 3.38       |
| F4   | 2    | 1000     | 100      | 20.00    | 0.63     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 1.60       |
| F5   | 2    | 1000     | 100      | 20.00    | 0.95     | 0.09     | 0.50     | 0.31     | 0.14   | 0.00     | 0.00   | 0.00       |
| F6   | 2    | 1000     | 100      | 20       | 0.77     | -1       | -1       | -1       | 0.00   | 20.00    | 1.00   | 1.31       |
| F7   | 2    | 1000     | 100      | 20.00    | 2.11     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.47       |
| F8   | 2    | 1000     | 100      | 20.00    | 2.48     | -25.7418 | -25.7418 | -25.7418 | 0.00   | 20.00    | 1.00   | 0.40       |
| F9   | 2    | 1000     | 100      | 20.00    | 2.41     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.42       |
| F10  | 2    | 1000     | 100      | 20.00    | 2.21     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.45       |

### GA

采用单点交叉,单点变异,染色体交叉概率为0.9,变异概率为0.001

#### 维度变化与参数选择

| 函数              | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解 | 最差解 | 平均值 | 标准差 | 达优次数 | 达优率 | 精度时间比 |
| ----------------- | ---- | -------- | -------- | -------- | -------- | ------ | ------ | ------ | ------ | -------- | ------ | ---------- |
| $f_{1}(X)$:ACKLEY | 2    | 1000     | 100      | 20.00    | 3.77     | 0.23   | 7.96   | 2.49   | 2.01   | 0.00     | 0.00   | 0.00       |
| $f_{2}(X)$:SPHERE | 2    | 1000     | 100      | 20.00    | 2.39     | 0.00   | 11.79  | 1.31   | 2.96   | 2.00     | 0.10   | 0.04       |
| $f_{2}(X)$:SPHERE | 2    | 1000     | 100      | 20.00    | 2.31     | 0.00   | 0.00   | 0.00   | 0.00   | 18.00    | 0.90   | 0.39       |
| $f_{2}(X)$:SPHERE | 5    | 1000     | 100      | 20.00    | 2.48     | 0.00   | 0.00   | 0.00   | 0.00   | 20.00    | 1.00   | 0.40       |
| $f_{2}(X)$:SPHERE | 10   | 1000     | 100      | 20.00    | 2.17     | 0.00   | 0.00   | 0.00   | 0.00   | 18.00    | 0.90   | 0.41       |

#### 维度为2的基准测试函数

| 函数 | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解   | 最差解   | 平均值   | 标准差 | 达优次数 | 达优率 | 精度时间比 |
| ---- | ---- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ------ | -------- | ------ | ---------- |
| F1   | 2    | 1000     | 100      | 20.00000 | 3.21     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.31       |
| F2   | 2    | 1000     | 100      | 20       | 1.84     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.54       |
| F3   | 2    | 1000     | 100      | 20.00    | 0.53     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 1.89       |
| F4   | 2    | 1000     | 100      | 20.00    | 1.53     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.66       |
| F5   | 2    | 1000     | 100      | 20.00    | 1.81     | 0.05     | 0.80     | 0.34     | 0.19   | 0.00     | 0.00   | 0.00       |
| F6   | 2    | 1000     | 100      | 20.00    | 1.80     | -1       | -1       | -1       | 0.00   | 20.00    | 1.00   | 0.56       |
| F7   | 2    | 1000     | 100      | 20.00    | 3.13     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.32       |
| F8   | 2    | 1000     | 100      | 20.00    | 7.40     | -25.7418 | -25.7418 | -25.7418 | 0.00   | 20.00    | 1.00   | 0.14       |
| F9   | 2    | 1000     | 100      | 20.00    | 3.82     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.26       |
| F10  | 2    | 1000     | 100      | 20.00    | 3.23     | 0.00     | 0.00     | 0.00     | 0.00   | 20.00    | 1.00   | 0.31       |

### DE

#### 维度变化与参数选择

| 函数              | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解 | 最差解 | 平均值 | 标准差 | 达优次数 | 达优率 | 精度时间比 |
| ----------------- | ---- | -------- | -------- | -------- | -------- | ------ | ------ | ------ | ------ | -------- | ------ | ---------- |
| $f_{1}(X)$:ACKLEY | 2    | 1000     | 100      | 20       | 3.21     | 0.00   | 0.00   | 0.00   | 0.00   | 20.00    | 1.00   | 0.31       |
| $f_{1}(X)$:ACKLEY | 5    | 1000     | 100      | 20       | 3.20     | 0.00   | 0.00   | 0.00   | 0.00   | 20.00    | 1.00   | 0.31       |
| $f_{1}(X)$:ACKLEY | 10   | 1000     | 100      | 20       | 3.30     | 0.00   | 0.00   | 0.00   | 0.00   | 20.00    | 1.00   | 0.30       |
| $f_{1}(X)$:ACKLEY | 50   | 1000     | 100      | 20       | 3.16     | 0.00   | 0.00   | 0.00   | 0.00   | 20.00    | 1.00   | 0.32       |

#### 维度为2的基准测试函数

| 函数 | 维数 | 进化代数 | 种群大小 | 测试次数 | 运行时间 | 最好解   | 最差解   | 平均值   | 标准差 | 达优次数 | 达优率 | 精度时间比 |
| ---- | ---- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ------ | -------- | ------ | ---------- |
| F1   | 2    | 1000     | 100      | 20.00    | 3.77     | 0.23     | 7.96     | 2.49     | 2.01   | 0.00     | 0.00   | 0.00       |
| F2   | 2    | 1000     | 100      | 20.00    | 2.31     | 0.00     | 0.00     | 0.00     | 0.00   | 18.00    | 0.90   | 0.39       |
| F3   | 2    | 1000     | 100      | 20.00    | 1.48     | 0.00     | 0.00     | 0.00     | 0.00   | 14.00    | 0.70   | 0.47       |
| F4   | 2    | 1000     | 100      | 20.00    | 2.05     | 0.00     | 0.06     | 0.01     | 0.01   | 11.00    | 0.55   | 0.27       |
| F5   | 2    | 1000     | 100      | 20.00    | 1.83     | 0.10     | 15.33    | 1.29     | 3.38   | 0.00     | 0.00   | 0.00       |
| F6   | 2    | 1000     | 100      | 20.00    | 2.28     | -0.96531 | -0.12675 | -0.73333 | 0.23   | 0.00     | 0.00   | 0.00       |
| F7   | 2    | 1000     | 100      | 20.00    | 3.56     | 0.01     | 0.10     | 0.03     | 0.03   | 0.00     | 0.00   | 0.00       |
| F8   | 2    | 1000     | 100      | 20.00    | 5.89     | -25.7418 | -25.2109 | -25.6987 | 0.11   | 11.00    | 0.55   | 0.09       |
| F9   | 2    | 1000     | 100      | 20.00    | 3.83     | 0.00     | 0.08     | 0.02     | 0.02   | 11.00    | 0.55   | 0.14       |
| F10  | 2    | 1000     | 100      | 20.00    | 3.66     | 0.01     | 0.10     | 0.03     | 0.05   | 0.00     | 0.00   | 0.00       |



## 对比与分析

三种算法对比如下:

|      | 平均运行时间 | 平均达优率 | 平均精度时间比 |
| ---- | ------------ | ---------- | -------------- |
| PSO  | 1.566721     | 0.9        | 0.986432       |
| DE   | 2.83         | 0.90       | 0.50           |
| GA   | 3.07         | 0.33       | 0.14           |

选取具有代表性的ackley函数,PSO，DE，GA对2维函数的收敛曲线,分别如下图所示.

总体而言,PSO与DE的平均达优率相同,但PSO运行速度更快,而GA在单峰函数上表现良好,但在多峰函数上表现较差,经常会陷入局部最优解.根据收敛曲线可以看出通常GA是最快收敛的(即便有时会陷入局部最优),PSO的收敛速度快于DE.

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547966916905.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547970326696.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547977557647.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547983642648.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-16547986077079.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165479908282511.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165479951909612.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165480004735313.png" alt="output" style="zoom:36%;" />

<img src="%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.assets/output-165480064863614.png" alt="output" style="zoom:36%;" />

# 编程体会

本次实验我利用PSO，DE，GA三种智能优化算法求解了10个基准测试函数,并进行了统计分析与对比.我希望能够利用这次实验的机会,去对各智能优化算法的实际应用场景与效果有更加深入的认识,因而在实验开始前,我着重花费精力去设计了对比分析的策略.

策略主要考虑了三个方面,**一是维度变化的影响**,通过改变函数的维度,利用算法进行求解,我发现函数维度的改变虽然对算法的运行时间影响不大,但对pso算法的精度影响剧烈,而对DE算法影响稍小,求解很高维度的函数pso算法会极易陷入局部最优,除非增加种群数量来提升精度.而DE即便在很高的维度上也保持较高的精准度.**二是参数的选择**,特别是关于迭代次数与种群数量的参数,关于PSO算法的实践似乎表明,当算法陷入局部最优时,通过提升迭代次数很难跳出局部最优,而增加种群数量是一个有效的方法.**三是不同基准函数的影响**,在单峰函数上三种算法均取得了良好的效果,而面对存在大量局部最优解的多峰函数,GA极易陷入局部最优.而在收敛速度上GA>PSO＞DE．

总体而言，通过本次实验的学习，在实践中我对智能优化算法有了更深的认识，更加体会到其思想，并且一定程度上了解了其局限性，这对我此后的学习之旅大有裨益．

# 核心源代码

## PSO 

```python 

class PSO(object):
    def __init__(self, func, n_dim=None, pop=40, max_iter=150, lb=-1e5, ub=1e5, w=0.8, c1=0.5, c2=0.5,
                 constraint_eq=tuple(), constraint_ueq=tuple()
                ):

        self.func = func_transformer(func)# 将函数转换为可以调用的形式
        self.w = w  # 惯性常数
        self.cp, self.cg = c1, c2  # 参数分别控制个人最佳、全球最佳, cp 和 cg 是认知和社交参数,
        self.pop = pop  # 粒子数
        self.n_dim = n_dim  # 粒子的维数，也就是函数的变量数
        self.max_iter = max_iter  # 最大迭代次数

        self.lb, self.ub = np.array(lb) * np.ones(self.n_dim), np.array(ub) * np.ones(self.n_dim)# 定义粒子的下界和上界

        self.has_constraint = bool(constraint_ueq)# 判断是否有约束
        self.constraint_ueq = constraint_ueq# 判断是否有不等式约束
        self.is_feasible = np.array([True] * pop)# 判断是否满足约束

        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.pop, self.n_dim))# 初始化粒子位置,(粒子数,变量维度)
        v_high = self.ub - self.lb# 初始化粒子速度的上界
        self.V = np.random.uniform(low=-v_high, high=v_high, size=(self.pop, self.n_dim))  # 初始化粒子速度,(粒子数,变量维度)
        self.Y = self.cal_y()  # 获取所有粒子的目标函数值

        self.pbest_x = self.X.copy()  # 初始化个体最优位置,(粒子数,变量维度)
        self.pbest_y = np.array([[np.inf]] * pop)  # 初始化个体最优目标函数值,(粒子数,1)
        self.gbest_x = self.pbest_x.mean(axis=0).reshape(1, -1)  # 初始化全局最优位置,(变量维度)
        self.gbest_y = np.inf  # 初始化全局最优目标函数值(1)
        self.gbest_y_hist = []  # 初始化全局最优目标函数值的历史记录
        self.update_gbest()# 更新全局最优位置和目标函数值

        self.best_x, self.best_y = self.gbest_x, self.gbest_y  # 获取最优位置和最优目标函数值

    def check_constraint(self, x):
        # 收集所有不相等的约束函数
        for constraint_func in self.constraint_ueq:# 循环遍历所有不等式约束
            if constraint_func(x) > 0:# 如果不等式约束不满足，则返回False
                return False
        return True

    def update_V(self):# 更新粒子速度
        r1 = np.random.rand(self.pop, self.n_dim)# 初始化随机数,shape=(pop,dim)
        r2 = np.random.rand(self.pop, self.n_dim)# 初始化随机数,shape=(pop,dim)
        # 更新粒子速度,其中w是惯性权重，cp是个体最优惩罚因子，cg是全局最优惩罚因子
        # 个体认知是参数*(个体最优-当前位置)即往个人最好点走,全局认知是参数*(全局最优-当前位置)即往全局最好点走
        self.V = self.w * self.V + \
                 self.cp * r1 * (self.pbest_x - self.X) + \
                 self.cg * r2 * (self.gbest_x - self.X)

    def update_X(self):# 更新粒子位置
        self.X = self.X + self.V# 更新粒子位置,X=X+V
        self.X = np.clip(self.X, self.lb, self.ub)# 将粒子位置限制在上下界之间,clip函数是将粒子位置限制在上下界之间,如果越界，则取上下界的值

    def cal_y(self):
        # 计算x中每个x的y值
        self.Y = self.func(self.X).reshape(-1, 1)
        return self.Y

    def update_pbest(self):
        self.need_update = self.pbest_y > self.Y # 判断是否需要更新个体最优位置和目标函数值,大小为(粒子数,1),是否更优,即是否更小
        for idx, x in enumerate(self.X):# 循环遍历所有粒子
            if self.need_update[idx]:# 如果需要更新
                self.need_update[idx] = self.check_constraint(x)# 判断是否满足约束,如果满足约束，则更新个体最优位置和目标函数值

        self.pbest_x = np.where(self.need_update, self.X, self.pbest_x)# 如果需要更新，则更新个体最优位置,否则不更新,np.where(condition,x,y)
        self.pbest_y = np.where(self.need_update, self.Y, self.pbest_y)# 如果需要更新，则更新个体最优目标函数值,否则不更新

    def update_gbest(self):

        idx_min = self.pbest_y.argmin()# 获取个体最优目标函数值最小的粒子的索引
        if self.gbest_y > self.pbest_y[idx_min]:# 如果全局最优目标函数值大于个体最优目标函数值
            self.gbest_x = self.X[idx_min, :].copy()# 更新全局最优位置
            self.gbest_y = self.pbest_y[idx_min]# 更新全局最优目标函数值


    def run(self, max_iter=None, precision=None, N=20):# 运行算法
        for iter_num in range(self.max_iter):# 循环迭代
            self.update_V()# 更新粒子速度
            self.update_X()# 更新粒子位置
            self.cal_y()# 计算粒子目标函数值
            self.update_pbest()# 更新个体最优位置和目标函数值
            self.update_gbest()# 更新全局最优位置和目标函数值

            self.gbest_y_hist.append(self.gbest_y)# 将全局最优目标函数值记录到全局最优目标函数值历史中
        self.best_x, self.best_y = self.gbest_x, self.gbest_y# 将全局最优位置和目标函数值赋值给最优位置和目标函数值
        return self.best_x, self.best_y

```

## DE

```python
class DE:
    def __init__(self, func, n_dim, F=0.5,
                 size_pop=50, max_iter=200, prob_mut=0.3,
                 lb=-1, ub=1,
                 constraint_eq=tuple(), constraint_ueq=tuple()):
        self.func = self.func_transformer(func)# 将函数转换为可以调用的形式
        self.size_pop = size_pop  # 群体大小
        self.max_iter = max_iter    # 最大迭代次数
        self.prob_mut = prob_mut  # 杂交概率
        self.n_dim = n_dim# 变量维度
        self.F = F# 缩放因子
        self.V, self.U = None, None# 变异后的个体
        self.lb, self.ub = np.array(lb) * np.ones(self.n_dim), np.array(ub) * np.ones(self.n_dim)# 变量的上下界
        self.generation_best_X = []# 用于记录每一代的最优解
        self.generation_best_Y = []# 用于记录每一代的最优解的目标函数值

        self.all_history_Y = []# 用于记录所有迭代的目标函数值
        self.all_history_FitV = []# 用于记录所有迭代的适应度值
        # 约束条件
        self.has_constraint = len(constraint_eq) > 0 or len(constraint_ueq) > 0# 是否有约束条件
        self.constraint_eq = list(constraint_eq)  # 一个ceq[i] <= 0的不相等约束函数的列表
        self.constraint_ueq = list(constraint_ueq)  # ceq[i] = 0的相等函数列表
        self.crtbp()# 创建种群

    def func_transformer(self,func):# 将函数转换为可以调用的形式
        is_vector = getattr(func, 'is_vector', False)# 判断是否是向量函数
        if is_vector:# 如果是向量函数
            return func# 返回原函数
        else:
            if func.__code__.co_argcount == 1:# 如果参数个数为1
                def func_transformed(X):# 定义一个新的函数
                    return np.array([func(x) for x in X])# 返回一个向量, 其中每个元素是原函数的返回值

                return func_transformed
            elif func.__code__.co_argcount > 1:# 如果参数个数大于1

                def func_transformed(X):# 定义一个新的函数
                    return np.array([func(*tuple(x)) for x in X])# 返回一个向量

                return func_transformed#

    def x2y(self):# 将X转换为Y
        self.Y_raw = self.func(self.X)# 计算X的目标函数值
        if not self.has_constraint:# 如果没有约束条件
            self.Y = self.Y_raw# 返回原始目标函数值
        else:
            # constraint_eq，constraint_ueq 靠“罚函数”，也就是说，适应度的计算是这样的
            #约束条件的形式是隐函数列表
            penalty_eq = np.array([np.sum(np.abs([c_i(x) for c_i in self.constraint_eq])) for x in self.X])# 相等约束函数的惩罚, 其中c_i是第i个相等约束函数
            penalty_ueq = np.array([np.sum(np.abs([max(0, c_i(x)) for c_i in self.constraint_ueq])) for x in self.X])# 不相等约束函数的惩罚, 其中c_i是第i个不相等约束函数
            self.Y = self.Y_raw + 1e5 * penalty_eq + 1e5 * penalty_ueq# 返回目标函数值
        return self.Y

    def crtbp(self):# 创建种群
        # 创建种群
        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.size_pop, self.n_dim))# 创建随机种群, 其中low是下界, high是上界, size是种群大小
        return self.X


    def mutation(self):# 变异
        '''
        V[i]=X[r1]+F(X[r2]-X[r3]),
        其中i r1 r2 r3是随机生成的
        '''
        X = self.X# 变异前的个体
        random_idx = np.random.randint(0, self.size_pop, size=(self.size_pop, 3))# 随机生成的下标

        r1, r2, r3 = random_idx[:, 0], random_idx[:, 1], random_idx[:, 2]#R1 r2 r3不应该相等 这里r1,r2,r2都是(50,1)的随机数组

        # 这里F用固定值，为了防止早熟，可以换成自适应值
        self.V = X[r1, :] + self.F * (X[r2, :] - X[r3, :])# 变异后的个体 DE/rand/1 eg. X[r1, :]即由X[r1[i]] for i in range(50)组成的个体

        ##下界和上界在突变中仍然有效 
        mask = np.random.uniform(low=self.lb, high=self.ub, size=(self.size_pop, self.n_dim))#生成种群数量*变量个数的随机数数组
        self.V = np.where(self.V < self.lb, mask, self.V)# 变异后的个体 越界的随机替代, 其中mask是替代的值
        self.V = np.where(self.V > self.ub, mask, self.V)# 变异后的个体
        return self.V

    def crossover(self):# 交叉
        '''
        如果rand < prob_crossover，使用V，否则使用X
        '''
        mask = np.random.rand(self.size_pop, self.n_dim) < self.prob_mut# 生成随机数组,判断是否满足杂交概率
        self.U = np.where(mask, self.V, self.X)# 如果rand < prob_crossover，使用V(变异后的个体)，否则使用X(未变异的个体), 其中mask是判断条件
        return self.U

    def selection(self):# 选择
        '''
        贪婪挑选法
        '''
        X = self.X.copy()#交叉前的种群
        f_X = self.x2y().copy()#交叉前的种群的适应值
        self.X = U = self.U#交叉后的种群
        f_U = self.x2y()#计算交叉后的种群的适应值

        self.X = np.where((f_X < f_U).reshape(-1, 1), X, U)#f_X < f_U则使用X,否则使用U 即选择所有值小的数
        return self.X#

    def run(self):
        for i in range(self.max_iter):#最大迭代次数
            self.mutation()# 变异
            self.crossover()# 交叉
            self.selection()# 选择

            # 记录最优解
            generation_best_index = self.Y.argmin()# 记录最优解的下标
            self.generation_best_X.append(self.X[generation_best_index, :].copy())# 记录最优解的坐标
            self.generation_best_Y.append(self.Y[generation_best_index])# 记录最优解的目标函数值
            self.all_history_Y.append(self.Y)# 记录所有迭代的目标函数值
            # print(str(i)+"代:best_x"+str(self.X[generation_best_index, :])+"besty:"+str(self.Y[generation_best_index]))

        global_best_index = np.array(self.generation_best_Y).argmin()# 记录全局最优解的下标
        global_best_X = self.generation_best_X[global_best_index]# 记录全局最优解的坐标
        global_best_Y = self.func(np.array([global_best_X]))# 记录全局最优解的目标函数值
        return global_best_X, global_best_Y# 返回全局最优解的坐标和目标函数值

```

## GA

```python
class GA:
    def __init__(self):
        self.fitness = []#初始化适应度
        self.population = []    # 种群
        self.chromo_len = 6  # 染色体初始长度 #二进制位数#只适用于整数优化
        #   定义域
        self.min_domain_of_definition = 0#最小值
        self.max_domain_of_definition = 63#最大值
        self.max_x = 0#最大值的x
        self.num_individuals = 100  # 种群大小#密度越大，对求解越有利，但计算量也越大
        self.p_mutate = 0.01 # 变异概率#希望点的分布相对分散
        self.p_crossover = 0.9  # 染色体交叉概率
        self.choose=0.5

    @staticmethod
    def cal_fitness(individual):#计算适应度#即评价函数#此处即目标函数
        return 20 * individual - pow(individual, 2)#适应度函数

    #   十进制转化为2进制
    def ten_to_2_str(self, num):
        res = bin(num)[2:]# 去掉前面的0b
        lis = list(res)# 将字符串转换为列表
        while len(lis) < self.chromo_len:## 列表长度不足，补0
            lis.insert(0, '0')  # 头部补零
        return "".join(lis)  # 以指定的字符连接生成一个新的字符串。

    def create_population(self):
        self.population = []#初始化种群
        for i in range(0, self.num_individuals):
            num = randint(self.min_domain_of_definition, self.max_domain_of_definition)  # 定义域内随机生成一个数
            self.population.append(self.ten_to_2_str(num))  # 转换为二进制 编码:定义问题参数空间到编码空间的映射

    def get_fitness(self):
        self.fitness = []#初始化适应度
        for i in range(0, self.num_individuals):#遍历种群
            self.fitness.append(20*int(self.population[i], base=2) - pow(int(self.population[i], base=2), 2))#计算适应度

    # 得到适应度最大值
    def get_maximum_value(self):
        res = self.fitness[0]#初始化
        self.max_x = int(self.population[0], base=2)#2进制转10进制
        for index in range(len(self.fitness)):#遍历适应度
            if self.fitness[index] > res:#比较适应度
                res = self.fitness[index]#更新适应度
                self.max_x = int(self.population[index], base=2)#更新最大值的位置

        return int(res)

    # 得到适应度最小值
    def get_minimum_value(self):
        res = self.fitness[0]#初始化
        for num in self.fitness:#遍历适应度
            if num < res:#比较适应度
                res = num#更新适应度

        return int(res)

    # 对两个个体进行杂交
    def crossover(self, x1, x2):
        son = []#初始化子代
        p1 = randint(0, (1 << self.chromo_len) - 1)#随机生成一个定义域内的数,即随机确定一个断裂点
        for i in range(0, self.chromo_len):#遍历染色体
            if i < p1:#染色体的前半段
                son.append(x1[i])
            else:#染色体的后半段
                son.append(x2[i])

        return "".join(son)

    # 对杂交后代进行变异#基本位变异
    def mutate(self, son):

        i = randint(0, self.chromo_len - 1)#随机确定一个变异点
        tmp = list(son)#将字符串转换为列表
        if tmp[i] == '1':#如果是1
            tmp[i] = '0'#变为0
        else:#如果是0
            tmp[i] = '1'#变为1

        return "".join(tmp)


    def select(self):
        parents = []#初始化父代

        # 所有个体的适应度都一样，为了方便选择前两个个体作为双亲
        if self.get_maximum_value() == self.get_minimum_value():
            parents = [self.population[0], self.population[1]]#取前两个个体作为双亲
            return parents#返回父代
        #   p1 2是最大最小适应度中间的随机数
        p1 = randint(self.get_minimum_value(), self.get_maximum_value() - 1)#取最大最小适应度中间的随机数
        p2 = randint(self.get_minimum_value(), self.get_maximum_value() - 1)#取最大最小适应度中间的随机数
        if_cho1 = 0# 判断是否选择第一个个体
        if_cho2 = 0# 判断是否选择第二个个体
        #   父亲
        for i in range(0, self.num_individuals):
            m = self.fitness[i] # 第i个个体的适应值
            if p1 <= m:# 如果适应值大于p1  0-100 20:0.2 90:0.9
                parents.append(self.population[i])
                if_cho1 = 1
                break

        # parents1=0
        # parents2=0
        # #   轮盘赌选父亲 适应性越高的个体被选中的概率就越大 #个体的选择是以“累积概率”为标准的
        # total = 0  # 初始化适应度总和
        # for i in self.fitness:
        #     total += i  # 累加
        # r = randint(0, total)  # 随机生成一个0-total的数
        # s = 0  # 初始化累加值
        # for i in range(0, len(self.fitness)):#遍历适应度
        #     s += self.fitness[i]  # 累加
        #     if s >= r:  # 如果累加值大于随机数 即累计概率大于随机概率
        #         parents.append(self.population[i])
        #         parents1=i#记录父代的位置
        #         if_cho1 = 1#父亲被选
        #         break

        # #   母亲
        for j in range(0, self.num_individuals):#遍历个体
            m = self.fitness[j]#第j个个体的适应度
            if p2 <= m and i != j:#如果适应度大于p2 且不等于第j个个体
                parents.append(self.population[j])
                if_cho2 = 1
                break

        #   轮盘赌选母亲 适应性越高的个体被选中的概率就越大 #个体的选择是以“累积概率”为标准的
        # total = 0  # 初始化适应度总和
        # for i in self.fitness:
        #     total += i  # 累加
        # r = randint(0, total)  # 随机生成一个0-total的数
        # s = 0  # 初始化累加值
        # for i in range(0, len(self.fitness)):#遍历适应度
        #     s += self.fitness[i]  # 累加
        #     if s >= r and parents1!=i:  # 如果累加值大于随机数 即累计概率大于随机概率
        #         parents.append(self.population[i])#选择母亲
        #         parents2=i#记录父代的位置
        #         if_cho2 = 1#母亲被选
        #         break
            
        if if_cho1 and if_cho2:#如果父母都被选了
            return parents
        else:
            #   如果父母存在没有被选
            parents.clear()
            parents.append(self.population[0])
            parents.append(self.population[1])
            return parents

    def solve(self, times):

        #   初始化种群
        self.create_population()
        max_value_list=[]
        #   初始为0代
        generations = 0
        while generations != times:#不满足迭代次数
            #   存新种群
            new_population = []
            #   获取适应度
            self.get_fitness()

            while len(new_population) != len(self.population):#不满足种群大小
                # 选择父母
                parents = self.select()
                while True:
                    son = parents[0]#初始化为父亲
                    #   如果会交叉(满足概率)
                    if randint(0, 99) / 100 < self.p_crossover:
                        son = self.crossover(parents[0], parents[1])#双亲杂交

                    #   如果会变异(满足概率)
                    if randint(0, 99) / 100 < self.p_mutate:
                        son = self.mutate(son)#变异

                    new_population.append(son)
                    break

                    # # 如果孩子比父母更优秀，放入新种群中 跳出while并选择下一个父母
                    # if GA.cal_fitness(int(son, base=2)) >= GA.cal_fitness(int(parents[0], base=2)) and GA.cal_fitness(int(son, base=2)) >= GA.cal_fitness(int(parents[1], base=2)and randint(0, 99) / 100>self.choose):
                    #     new_population.append(son)
                    #     break

            #   用更优秀的新种群代替老种群
            self.population = new_population
            self.get_fitness()#获取适应度
            max_value = self.get_maximum_value()#获取最大适应度
            # max_value_list.append(max_value)
            print(f"第 {generations} 代在 {self.max_x}处取得最优函数值为 {max_value}")
            generations += 1

        max_value = self.get_maximum_value()#获取最大适应度
        print(max_value)#打印最优函数值
```

## 可视化与数据分析

```python
# %%
n_var=2
def GRIEWANK(x):
    # x=np.array(x)
    x1,x2=x
    part1=1 / 4000 * (np.power(x1, 2)+np.power(x2, 2))
    part2=np.cos(x1/1)*np.cos(x2/2)
    res=1 +part1   - part2
    return res
de = DE(func=GRIEWANK, n_dim=n_var, size_pop=100, max_iter=1000, lb=[-40]*n_var, ub=[40]*n_var)
global_best_X, global_best_Y=de.run()
plt.plot(de.generation_best_Y,label='DE')# 绘制全局最优目标函数值历史
#标注为de
plt.legend()
pso = PSO(func=GRIEWANK, n_dim=n_var, pop=100, max_iter=1000, lb=[-40]*n_var, ub=[40]*n_var, w=0.8, c1=0.5, c2=0.5)
pso.run()
plt.plot(pso.gbest_y_hist,label='PSO')# 绘制全局最优目标函数值历史
plt.legend()


ga = GA(func=GRIEWANK, n_dim=n_var, size_pop=100, max_iter=800, prob_mut=0.001, lb=[-40]*n_var, ub=[40]*n_var, precision=1e-7)
best_x, best_y = ga.run()
plt.plot(ga.generation_best_Y,label='GA')# 绘制全局最优目标函数值历史
plt.legend()


plt.xlabel('迭代次数')
plt.ylabel('目标函数值')
plt.title('GA:'+'GRIEWANK函数:'+str(n_var)+'维')
plt.show()
```



