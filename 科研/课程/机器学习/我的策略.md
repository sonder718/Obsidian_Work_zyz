# 任务一
## 实验一
### 问题理解与分析
实现拉普拉斯修正的朴素贝叶斯分类器，以西瓜数据集3.0为 训练集，对“测1”进行判别。【教材习题7.3】
![](attachments/Pasted%20image%2020220524224021.png)
![](attachments/Pasted%20image%2020220524224051.png)

### 算法原理阐述
![](attachments/Pasted%20image%2020220524235810.png)

![](attachments/Pasted%20image%2020220524235604.png)
### 算法设计思路
1.计算先验概率 
![](attachments/Pasted%20image%2020220525155814.png)
2.对于离散属性直接计算条件概率
![](attachments/Pasted%20image%2020220525160503.png)
3.对于连续属性计算C类样本在第i个属性上的均值与方差,概率密度函数计算条件概率
![](attachments/Pasted%20image%2020220525162526.png)
![](attachments/Pasted%20image%2020220525162558.png)
4.预测时将先验概率与所有条件概率相乘计算后验概率
![](attachments/Pasted%20image%2020220525162717.png)
5.后验概率高的类别为预测结果
其原理如下
![](attachments/Pasted%20image%2020220525163005.png)
## 实验二
### 问题理解与分析
编程实现AdaBoost模型，不剪枝决策树为基学习器，在西瓜 数据集3.0上训练一个AdaBoost集成，并与教材图8.4进行比较。【教 材习题8.3】
### 算法原理阐述
#### 什么是AdaBoost模型
基于基学习器的线性组合
每次基于之前的结果调整**样本的权重**，并且基于本树的误差率给予权值。多棵树组成的加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类学习方法，叫做Adaboost。
![](attachments/Pasted%20image%2020220525163057.png)
#### 算法过程
![](attachments/Pasted%20image%2020220525163233.png)
#### 算法结果
![](attachments/Pasted%20image%2020220525163357.png)
#### 值得注意的点
![](attachments/Pasted%20image%2020220525173612.png)
### 算法设计思路
#### 初始化样本权重分布
![](attachments/Pasted%20image%2020220525164149.png)
#### 基于样本分布训练基学习器
关键在选择最佳划分属性时利用了分布D
普通的基尼指数
![](attachments/Pasted%20image%2020220525175401.png)
加上分布后的基尼指数
![](attachments/Pasted%20image%2020220525184333.png)
#### 计算误差 
![](attachments/Pasted%20image%2020220525164812.png)![](attachments/Pasted%20image%2020220525164824.png)![](attachments/Pasted%20image%2020220525164732.png)
#### 分类器权重更新
![](attachments/Pasted%20image%2020220525165157.png)
![](attachments/Pasted%20image%2020220525165211.png)
#### 更新样本分布
![](attachments/Pasted%20image%2020220525173408.png)
![](attachments/Pasted%20image%2020220525165431.png)


## 实验三
### 问题理解与分析
基于西瓜数据集3.0，设计一种提升k近邻分类器性能的集成学习方法，并与以决策树桩位基学习器Bagging集成学习结果比较。 【教材习题8.10&&8.5】
### 算法原理阐述
### 算法设计思路

# 任务二：kaggle澳大利亚下雨


问题理解与分析、算法原理阐述、算法设计思路、数据预处理、实验流程分析、实验结果分析、 代码结构分析、解决问题及主要收获、标注参考来源等

## 问题理解与分析

任选一个Kaggle数据集，详细分析并全面比较至少3种学过的机 器学习模型、以及1种自学的改进/新模型的性能优劣。【额外做实验比较的模型总数不允许超过10种】。

学过的机器学习模型:
自学的改进/新模型:改进逻辑回归,改进knn,XGboost
## 算法原理阐述

## 算法设计思路
1. 数据分析
2. 特征工程(由弱到强的特征工程比对)
3. 对比特征压缩方法[[译] 对比归一化和标准化 —— 量化分析 - JavaShuo](http://www.javashuo.com/article/p-zbeexlus-hx.html)
4. 对比多种模型（SVM，单决策树，随机森林）
5. 如何平衡混淆矩阵
6. 可视化方法[Plotly guide: Customize for better visualizations | Kaggle](https://www.kaggle.com/code/desalegngeb/plotly-guide-customize-for-better-visualizations/notebook)
7. 目前最高准确率90.33，93.02
8. smote算法
## 数据预处理
### 探索性数据分析(EDA)

## 实验流程分析

## 实验结果分析


