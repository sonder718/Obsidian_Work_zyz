#    基于RGBD数据的障碍物检测方法研究

**项目名称：基于RGBD数据的障碍物检测方法研究**

**申 报 人：张一卓**

**联系方式：15290873718**

**指导老师：孙琨**

 

#    项目简介(200字以内):

在盲人辅助系统、移动机器人与无人驾驶等领域，准确、实时地获取到运动过程中的环境信息，对避免事故的发生具有重大意义。随着计算机视觉技术的进步，双目相机等被广泛应用于上述领域。如何有效利用其感知的RGBD数据进行准确高效的障碍物检测成为一个热门话题。本项目在2021年《**基于双目相机的盲人户外智能语音辅助系统**》大创项目的基础上，针对RGBD数据的障碍物检测方法进行研究，致力于提出一种兼具实时性和准确性的障碍物检测算法。

#    项目申报理由(主要包括项目成员的知识储备、优势以及前期准备):

知识储备：

1、 课程基础：团队成员已经学习了计算机图形学、计算机视觉、人工智能、机器学习、智能优化算法等课程。

2、 语言基础：团队成员具有良好的外语基础，具有良好的文献阅读能力。

2、编程基础：团队成员已掌握C/C++、Python、Java等编程语言，对C#、Kotlin也有着一定程度的了解。

3、成绩基础：团队成员热爱编程，数据结构等主页课基础扎实，成绩优异，平均学分绩点3.8+，专业排名均位于年级前25%。

4、算法基础：团队成员熟悉传统的模式识别图像处理算法、常用的深度学习目标检测与语义分割算法。

5、工具基础：团队成员能够熟练使用Opencv等工具，曾多次使用Pytorch、Tensorflow等深度学习框架。

 

优势:

1、 团队成员已经成功结题《基于双目相机的盲人户外智能语音辅助系统》，对双目相机的使用有着丰富的经验。

2、 团队成员有着《基于深度学习的场景文字识别》深度学习项目经历。

3、 团队成员进行过《纵深场景下多目标人脸检测算法》的研究，对人脸检测与人头检测算法与工程部署具有一定的实战经验。

4、 团队成员具有使用自标注数据集,租用云服务器,在Linux系统下训练YOLO和Faster Rcnn等模型的实践经历。

5、 团队成员进行过基于SLIC的超像素分割算法的研究。

6、 团队成员具有较强的协作精神，多次使用git进行协同开发。

7、 团队成员具有强烈的社会责任感和团队意识，对该项目兴趣浓厚。

前期准备:

1、   基于双目相机的盲人户外智能语音辅助系统中实现了一种简易的利用RGBD信息进行障碍物检测的方法，对障碍物检测有一定了解。

2、 关于障碍物检测方法的调研：

在障碍物检测中，对障碍物的确认和距离的快速测量至关重要。使用传感器虽然可以提高检测系统的精度和鲁棒性，但也显著提高了硬件和软件系统的复杂性以及成本。如果使用单目相机，在测距的范围和距离方面，又要面临不可调剂的矛盾即摄像头的视角越宽，所能探测到精准距离的长度越短，视角越窄，探测到的距离越长。同时少数的单面视觉测距系统测距仍然要依赖额外的测距仪来实现，这些都限制了障碍物检测方法的进一步推广应用。

3、RGBD数据的障碍物检测可行性分析

基于RGBD数据的障碍物检测方法,主要分为障碍物识别和检测长度,宽度两部分.在障碍物形状不规则的前提下,通过摄像头实时采集图像传输到数据处理中心,用改良的帧差法、最小矩形法匹配法和图像处理等方法来确定障碍物轮廓,利用深度图像及其阈值得出障碍物距摄像头的相对位置,同时,用坐标转换法计算出障碍物的高度与宽度。

4、论文阅读

阅读了近年来关于三维目标检测，小障碍物检测的顶会论文，对当今研究现状有一定了解。

 

 

#    项目研究目的和解决的主要问题:

研究目的:

随着社会经济的迅速发展，汽车的数量不断增长，同时也带来了交通事故和交通拥堵问题的加剧，于是人们逐渐将目光投向了与计算机技术融合的无人驾驶技术。无人驾驶技术是未来汽车行业发展的主要方向，通过计算机精密的计算能力和快速而低成本的基于视觉的目标检测，能够在一定程度上避免人在驾驶过程中非客观原因导致的错误决策，有效地解决交通问题。无人驾驶车辆在行驶过程中需要感知环境，根据所感知的道路、车辆、障碍物等信息，控制车辆的转向和速度，从而使车辆能够安全行驶。

本项目针对自动驾驶场景，基于车载传感器的RGB-D数据，对行驶过程中的障碍物进行检测，确保车辆能够识别障碍物，并调整自身的行驶情况以躲避障碍物，达到安全行驶的目的。

 

解决的主要问题:

1. 检测截断对象：RGBD相机获取的图像信息往往无法完整地呈现整个车辆周围的所有情况，在图像边缘可能存在障碍物被截断的现象。项目在图像边缘区域进行显示解耦，提高截断对象检测的性能。

2. 提高检测精度：将本项目的方法应用于自动驾驶数据集KITTI上，面对大部分的障碍物和截断对象，都可以检测成功。

3. 判定障碍物危险等级：在行驶过程中，如果遇到其他车辆，对方可能主动避让；而若是一般障碍物，就需要无人驾驶车自行避开；此外，也有可能遭受其他突发情况，例如：路面坍塌、高空坠物等。通过学习算法对障碍物危险等级进行判定，使得在同时遭遇多种障碍物时做出优先决策。

4.  相机抖动问题：由于相机常处于运动环境中，需要抑制相机抖动引起的分割误差

5. 意外小障碍物：当前主流的自动驾驶数据集通常只假设场景中的某些固定类别的对象，而忽略了现实世界中意外的小障碍物等不可预见的危险，碎片、砖块、石块和货物等意外道路危险通常成为了图像中最危险和最难检测的因素。

 

 

 

#    项目的研究背景及项目主要研究内容

**研究背景:**

障碍物检测的应用前景十分广阔，具有极大的实际应用意义，是盲人辅助系统、无人驾驶与自主移动机器人等领域中的关键技术。由于近年来深度学习领域以及3D目标检测等领域的进展,本项目具备了一定的技术基础。

根据传感器类型不同，障碍物检测方法有：激光雷达、超声波、结构光、双目摄像机等。其中，使用双目摄像机可以获得丰富的彩色图像信息和深度信息，设备简单、成本低廉，基于双目立体视觉的目标检测方法与基于RGBD数据的障碍物检测是近年来研究的热点之一。

单目视觉系统下利用**RGB信息**进行障碍物检测是其中一个研究方向，国内外研究者主要使用视觉数据中的颜色信息、边缘信息、光流变化等展开研究。利用边缘信息是一种比较简易的分割障碍物与背景的方法，canny算子、Mean-shift算子等都可用于提取边界信息，但易受到噪声影响。使用颜色信息的时候，A.C.She等人提出一种算法在图像的每个色彩通道上建立直方图，然后在一定阈值范围内进行颜色分割，最终可以得到自由区域和疑似障碍物区域[1]。而使用光流信息时，光流法[2]常用于动态场景下障碍物检测，如HW Ho 等人[3]使用光流特征结合无监督学习方法对图像中的障碍物像素实现分割。总体而言，传统的单目视觉系统都利用了环境的色彩信息或阴影信息，当环境光照变化剧烈、色彩分界不明显时，方法的有效性会降低。

立体视觉能够获得图像中物体的三维信息，可以得到物体的几何特性，因此越来越多的研究在立体视觉的基础上综合各种分割方法来检测障碍物。深度图像为更全面、更精准的三维感知提供了条件，同时也对软件算法的实时性和鲁棒性提出了更高的要求。

**单纯深度图**可以进行障碍物检测,如Wang等人[4] 提出一种利用Meanshift分割实现障碍物检测的算法,但受限于光滑物体表面反射等原因会造成深度图缺失,同时单纯利用深度信息不能区分不同类型的路面，因而利用RGB-D信息进行障碍物检测是当下的热门方向。

**基于RGBD信息**进行障碍物检测，常见的想法是将其看做一种通用的3D目标检测任务，三维目标检测是一种基于图像几何和统计特征的三维分析方法，其要求从传感数据中获取特定目标的三维包围框，包括目标类别、中心位置、尺寸、方向等信息。现有的三维目标检测方法可大致分为单阶段方法和两阶段方法[5]。单阶段方法的计算速度较快，不需要细化就可直接估计目标的包围框．两阶段方法首先从场景中提取感兴趣区域(Region of Interest,ROI)或候选框（Region Proposal）作为候选目标，再通过分类得分和位置回归对这些候选目标进行分类和细化。单阶段方法可直接生成检测框目前主要有两种方式：(1)首先生成二维检测框，再结合深度信息进行三维框回归；(2)端到端直接生成三维检测框。

该任务的关键点在于如何在特征学习中巧妙地将RGB与深度信息协调起来[6]。近年来涌现出了许多相关研究，Wang等人[7]提出将基于图像的深度图转换为伪激光雷达表示，Li等人[8] 用了物体的语义特性和密集约束，关联双目图像的同时进行目标检测，Zhang等人[9] 关注物体截断问题，提出了边缘融合模块，将外部目标的特征学习和预测解耦。Wang等人[10] 提出了一种深度条件动态消息传播网络，有效地将多尺度深度信息与图像上下文相结合，而不是采用复杂的伪激光雷达方法。

许多方法只支持在交通道路上预先定义的一些正常障碍物，而不支持对道路上的任意障碍物进行扩展，Hua等人[11]利用光流监控与两阶段语义分割网络提出了一种对小障碍物进行检测的方法，Sun等[12]也关注了现实世界中意外的小障碍物的问题，提出了一种包含意外障碍物的检测，用于RGB-D语义分割的实时融合网络。

总体来说障碍物检测的应用环境复杂多变，目前没有一种通用的障碍物检测方法能够对道路上可能出现的各种类型障碍物进行高效实时的检测，特别是结合深度学习技术对意外障碍物检测的研究还较少，鉴于RGB-D数据的优越性，基于RGB-D数据进行障碍物检测具有广阔的研究前景。

**项目主要研究内容:**

本项目致力提出一种新的基于RGB-D数据的障碍物检测方法，使其能够在盲人辅助系统、无人驾驶与自主移动机器人等领域具有较强的实用性。

本项目对截断对象与意外障碍物等进行特别的关注，尝试结合RGBD语义分割和障碍物检测，通过两阶段语义分割进行障碍物检测。具体来说，尝试利用运动模糊增强和光流监督等技术，以获得更准确和稳定的障碍物分割，此外利用边缘融合模块将截断的物体解耦，从而更好的处理截断对象。

 

[1] SHE A C, HUANG T S. Segmentation of road scenes using color and fractal-based texture classification[C]//Proceedings of 1st International Conference on Image Processing: 卷 3. IEEE, 1994: 1026-1030.

[2] BARRON J L, FLEET D J, BEAUCHEMIN S S. Performance of optical flow techniques[J]. International journal of computer vision, 1994, 12(1): 43-77.

[3] HO H W, DE WAGTER C, REMES B D W, 等. Optical-flow based self-supervised learning of obstacle appearance applied to MAV landing[J]. Robotics and Autonomous Systems, 2018, 100: 78-94.

[4] WANG T, BU L, HUANG Z. A new method for obstacle detection based on Kinect depth image[C/OL]//2015 Chinese Automation Congress (CAC). 2015: 537-541. DOI:10.1109/CAC.2015.7382559.

[5] 王亚东;田永林;李国强;王坤峰;李大字; 基于卷积神经网络的三维目标检测研究综述[J]. 模式识别与人工智能, 2021, 34.

[6] HOU S, WANG Z, WU F. Deeply exploit depth information for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 2016: 19-27.

[7] WANG Y, CHAO W L, GARG D, 等. Pseudo-LiDAR From Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving[C/OL]//2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Long Beach, CA, USA: IEEE, 2019: 8437-8445[2022-05-19]. https://ieeexplore.ieee.org/document/8954293/. DOI:10.1109/CVPR.2019.00864.

[8] LI P, CHEN X, SHEN S. Stereo R-CNN Based 3D Object Detection for Autonomous Driving[C/OL]//2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Long Beach, CA, USA: IEEE, 2019: 7636-7644[2022-05-19]. https://ieeexplore.ieee.org/document/8953542/. DOI:10.1109/CVPR.2019.00783.

[9] ZHANG Y, LU J, ZHOU J. Objects are Different: Flexible Monocular 3D Object Detection[C/OL]//2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Nashville, TN, USA: IEEE, 2021: 3288-3297[2022-05-17]. https://ieeexplore.ieee.org/document/9578273/. DOI:10.1109/CVPR46437.2021.00330.

[10]  WANG L, DU L, YE X, 等. Depth-conditioned Dynamic Message Propagation for Monocular 3D Object Detection[C/OL]//2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2021: 454-463. DOI:10.1109/CVPR46437.2021.00052.

[11]  HUA M, NAN Y, LIAN S. Small Obstacle Avoidance Based on RGB-D Semantic Segmentation[C/OL]//2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW). Seoul, Korea (South): IEEE, 2019: 886-894[2022-05-19]. https://ieeexplore.ieee.org/document/9021979/. DOI:10.1109/ICCVW.2019.00117.

[12]  SUN L, YANG K, HU X, 等. Real-time fusion network for RGB-D semantic segmentation incorporating unexpected obstacle detection for road-driving images[J/OL]. IEEE Robotics and Automation Letters, 2020, 5(4): 5558-5565. DOI:10.1109/LRA.2020.3007457.

 

#    项目设计路线(项目方案、进程、安排等):

方案：

![img](%E5%A4%A7%E5%88%9B%E7%AB%8B%E9%A1%B9-%E9%9A%9C%E7%A2%8D%E7%89%A9%E6%A3%80%E6%B5%8B.assets/clip_image002.gif)

 

进度：

第一阶段（2022年6-9月）：

1. 阅读文献资料并调研无人驾驶过程中的路面障碍物情况；

2. 建立道路图像数据集，并对图像特征进行分析；

3. 研究目前已有的3D检测算法，包括PointFusion、Frustum PointNets并进行复现。

第二阶段（2022年10-12月）：

1. 基于基础模型进行改进，添加边缘融合模块，将特征映射的边缘解耦以预测长尾截断对象。

2. 搭建两阶段语义分割编解码网络，对图像进行分割以获得道路掩码，然后从提取的道路区域获得更准确的障碍物区域。

3. 基于CenterNet目标检测网络，生成heatmap热力图，采用仿射变换warpAffine，搭建基础识别模型。

第三阶段（2023年1-2月）：

1.   对光流监督与运动模糊增强模块进行改进

2.   对边缘融合模块进行改进

第四阶段（2023年3-6月）：

1.   在多个数据集上进行测试，与当下主流算法对比

2.   测试优化模型结构

3.   在实际场景中应用测试

 

 

#    项目特色与创新点(200字以内):

1. 结合RGBD语义分割和障碍物检测，通过两阶段语义分割，能够检测道路上意外的小型但潜在危险的障碍物。

2. 利用相邻帧之间的光流监控来保持分割网络的时间一致性，利用运动模糊增强来抑制相机抖动引起的分割误差。

3. 对图像中的截断对象进行特别处理，利用边缘融合模块将截断的物体解耦。对截断对象有更好的性能。

#    项目预期成果:

提出一种兼具实时性和准确率的障碍物检测方法，并应用到基于双目相机的盲人户外智能语音辅助系统上。

 

 