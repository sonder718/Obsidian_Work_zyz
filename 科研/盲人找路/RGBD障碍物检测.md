# Small Obstacle Avoidance Based on RGB-D Semantic Segmentation:star:

[Small Obstacle Avoidance Based on RGB-D Semantic Segmentation (thecvf.com)](https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Hua_Small_Obstacle_Avoidance_Based_on_RGB-D_Semantic_Segmentation_ICCVW_2019_paper.pdf)

本文提出了一种新型的道路机器人避障系统，该系统配有RGB-D传感器，可以捕捉机器人前进的场景。该系统的目的是让道路机器人能够自主地、持续地移动，即使遇到小障碍物，也不会发生任何碰撞，而现有的解决方案往往无法实现这一点。对于每个输入的RGB-D图像，系统使用新的两阶段语义分割网络，然后进行形态学处理，生成包含道路和障碍物的精确语义地图。基于地图，采用局部路径规划以避免可能的碰撞。此外，采用光流监控和运动模糊增强训练方案，提高相邻帧之间的时间一致性，克服摄像机抖动带来的干扰。通过各种实验表明，该体系结构在室内和室外场景下都具有较高的性能。

避障是智能移动机器人的一个基本组成部分，其核心是拥有一个环境感知模块，帮助识别可能阻碍机器人前进的障碍物。特别是在某些情况下，应仔细考虑小障碍物，如自动驾驶、巡逻机器人和盲引导，如图1所示。在自动驾驶中，当汽车高速行驶时，道路上的砖块等小障碍物可能会导致汽车翻车。在盲人指导下，视力受损的人对这样的小物体很脆弱，即使在道路上只有3厘米高。对于作为社区警务人员的巡逻机器人来说，应该检测一些散布在道路上的残余物，将其作为障碍物避免，或者将垃圾溢出以提醒注意，例如垃圾桶和石块

基于距离和基于外观的方法是执行障碍物检测任务的两种主要方法

但前者有共同的缺点，很难发现小障碍物并区分不同类型的路面，因此很难将人行道路面与相邻的草地区分开来，这在城市环境中很常见

另一方面，基于外观的方法【19、10、23、17、24】不受上述问题的影响

因为他们将障碍物定义为外观不同的物体，这在我们的研究中是一个更重要的特征，与道路不同，而前者仅将障碍物定义为从道路一定高度升起的物体。基于外观的避障方法的主要步骤之一是对可进入区域和其他物体进行语义分割，以便机器人做出避障和路径规划决策

对于基于外观的传感器，我们有单目摄像头和立体摄像头。前者输出纯视觉线索（即RGB信息），语义分割网络难以准确区分真实障碍物和外观变化，例如不同的道路颜色和道路标记。后者为RGB图像提供额外的深度通道。最近的研究表明，结合RGB和深度信息可能会提高语义分割网络的性能【12、9、13】

利用语义分割进行障碍物回避是近年来的一个新课题[15、20、8]，但这些方法应用于有限场景或对小障碍物不敏感

本文提出了一种基于RGB-D语义分割的小型避障系统，可广泛应用于室内外场景。

**这项工作的主要贡献如下：1）**

**提出了一种用于障碍物分割的两级RGB-D编解码网络，该网络首先对图像进行分割，得到道路掩模，然后从提取的道路区域中得到更准确的障碍物区域，甚至是较小的障碍物区域。2） 为了保持分割网络的时间一致性，提出了相邻帧之间的光流监控，这对于摄像机移动时稳定的障碍物检测至关重要。3） 提出了一种基于运动模糊的数据增强方案来抑制摄像机抖动引起的分割误差。4） 提出了一种基于RGB-D语义分割的小型避障系统，并基于室内外场景的实际数据集对其进行了评估**

第一个自主移动机器人使用Nilsson开发的基于外观的障碍物检测方法[19]，名为Shakey。它可以通过对单色图像进行边缘检测来检测障碍物。按照尼尔森的步骤，霍斯威尔还将边缘检测方法应用于他的移动机器人Polly[10]，该机器人在现实环境中运行。Shakey和Polly使用的边缘检测方法仅在地板纹理较少且环境照明均匀的情况下表现良好。它对地板颜色变化和照明条件非常敏感

除了边缘信息外，其他一些信息也被用于障碍物检测。Turk和Marra利用颜色信息【23】通过减去视频的连续帧来检测障碍物。Lorigo提出了一种在纹理地板上同时使用颜色信息和边缘信息的算法【17】。Lorigo假设机器人正前方没有障碍物，并将该区域作为参考区域来查找障碍物。Ulrich使用候选队列和参考队列改进了Lorigo算法【24】。然而，在移动机器人能够自主移动之前，他们需要先引导它几米，以形成正确的参考区域。如果参考区域外的道路由于意外的阴影或反射而与参考区域不同，它也将被错误地归类为障碍物

最近，一些其他基于外观的避障方案也被提出。Ghosh和Wei提出了基于立体视觉的障碍物检测方法[7,26]。在这些方法中，视差图用于分析周围环境和确定障碍物。然而，立体图像计算的视差图在复杂环境下，尤其是在存在小障碍物的情况下，鲁棒性不够。杨提出了一种基于RGB和深度图像的盲引导系统[27]。该方法利用RGB图像获取环境的语义图，然后结合深度图像感知地形。然而，该方法侧重于行人和车辆等可通过区域的分割，而无法检测出小的障碍物。对于小型障碍物，[20，8]探讨了以自主驾驶场景为重点的障碍物检测问题。在这些方法中，首先将驾驶场景中常见的预定义障碍类别放置在道路上初始化障碍数据集，然后使用RGB和深度信息训练障碍分割模型。**然而，该方法只支持在交通道路上预先定义的一些正常障碍物，而不支持对道路上的任意障碍物进行扩展。**



如图2所示，提出的障碍物检测和回避系统包括几个步骤：基于RGB-D的**两阶段语义分割**、**形态学处理**、局部目的地设置和路径规划。两阶段语义分割**将输入的RGB-D图像转换为原始二值图像**，然后在形态学处理中进行平滑处理。因此，该模块生成一个校准的二值图像，其中每个像素都标记为道路或障碍物。然后将二值图像传递给避障模块，以确定目的地和可行走路径。整个过程在机器人移动过程中反复进行

![image-20220518155853409](RGBD%E9%9A%9C%E7%A2%8D%E7%89%A9%E6%A3%80%E6%B5%8B.assets/image-20220518155853409.png)

3.1. 两阶段RGB-D语义分割拟议的两阶段RGB-D语义分割架构如图3所示。对于第一阶段，网络的RGB-D编码器部分与RedNet[13]之前的工作类似，后者有两个卷积分支。RGB和depth分支均采用ResNet架构，去掉了全局平均池层和完全协同进化层。分别对RGB和深度通道提取不同尺度的特征。对于每个卷积运算，在ReLU函数之前执行批归一化。来自两个分支的特征贴图在每个比例下进行融合。融合操作被表示为fRGB⊕ fD，其中fRGB表示RGB分支的特征映射，fD表示深度分支的特征映射，⊕ 表示元素直接求和。**两个连续的视频帧Ip和Ic同时输入编码器**，其中Ip和Ic表示前帧和当前帧。Ip和Ic的RGB通道被馈送到深流网络以估计其光流场Fc→p在第一阶段

语义信息及其空间位置关系编码在特征地图中。连续视频帧具有高度相似性，因此我们可以通过其流场将前帧的特征映射传播回当前帧[30]。传播的特征映射也应该与原始当前帧生成的特征映射高度相似。在这项工作中，我们选择了FlowNet[6]初始架构，该架构在[30]中进行了修改，以满足精度和速度之间的权衡。由于特征贴图具有不同的空间分辨率，流场将双线性调整为与特征贴图相同的分辨率，以便传播。因此，给定前车架fea上的位置x-

![image-20220518160148919](RGBD%E9%9A%9C%E7%A2%8D%E7%89%A9%E6%A3%80%E6%B5%8B.assets/image-20220518160148919.png)

![image-20220518160349634](RGBD%E9%9A%9C%E7%A2%8D%E7%89%A9%E6%A3%80%E6%B5%8B.assets/image-20220518160349634.png)

在这项研究中，我们提出了一种基于深度语义分割神经网络的道路机器人行走路径自动生成体系结构。为了获得更准确、更稳定的障碍物分割，提出了基于运动模糊增强和光流监控的两阶段分割方法，采用形态学处理对障碍物分割进行细化，并基于精确的障碍物地图进行局部路径规划，生成无碰撞路径

实验结果表明，该方法在室内外各种场景下都能很好地工作，即使有小的障碍物或捕捉模糊。两阶段分割提高了小障碍物检测的精度，基于模糊的数据增强和光流监控提高了稳定性

# Real-time Fusion Network for RGB-D Semantic Segmentation Incorporating Unexpected Obstacle Detection for Road-driving Images

[2002.10570.pdf (arxiv.org)](https://arxiv.org/pdf/2002.10570.pdf)

环境感知是智能机器人和系统在目标分类、自主驾驶和定位方面的一项重要任务。近年来，基于深度卷积神经网络（CNN）的语义分割方法在该领域取得了显著的进展[1][2][3]。作为一种应用于自主驾驶的环境感知方法，安全性、准确性和效率是上层导航任务语义分割的关键因素。然而，碎片、砖块、石块和货物等意外道路危险成为自动驾驶图像中最危险和最难检测的因素。据美国汽车协会交通安全基金会（AAAFoundation for Traffic Safety）称，2011年至2014年间，道路上的碎片导致美国道路上发生了20多万起车祸，导致约39000人受伤，500多人死亡【4】。这些障碍物通常很小，但形状和类型都不固定，因此探测它们是一个具有挑战性的课题。这项工作的部分资金来自AccessibleMaps项目

本工作得到了杭州苏瑞影像科技有限公司的支持

1升。Sun、X.Hu和W.Hu是中国浙江大学现代光学仪器国家重点实验室{leo\u Sun，hxx\u zju，huweijian}@zju。埃杜。cn 2K。杨在德国凯伦卡尔斯鲁厄理工学院人类与机器人研究所工作。yang@kit.edu3K。王先生在中国浙江大学国家光学仪器工程技术研究中心工作wangkaiwei@zju.edu.cn（a）SwiftNet（b）RFNet图1。来自失物和失物数据集的示例以及相应的方法结果：（a）SwiftNet（错误分类为car的意外障碍物），（b）建议的RFNet（清晰一致的分割）

引起了机器人和计算机视觉界的兴趣。基于这些原因，有必要开发一种基于语义分割的方法，结合像素级意外障碍物检测

与昂贵的3D传感器（如激光雷达）相比，RGB摄像头是一种成本更低、分辨率更高的解决方案

基于RGB立体相机，曾有人尝试借助几何线索和CNN来检测小障碍物[5]，但仅依靠RGB图像中的明显信息不足以检测障碍物[6]

例如，井盖和小障碍物都可能导致图像中的渐变变化。深度图中的可穿越区域和障碍物在深度图中变化很大

深度图包含更多的位置和轮廓信息，可作为真实驾驶场景中对象的关键指示器。从这个意义上讲，外观和深度的适当结合有望改善

性能[6][7][8]。但大多数面向准确度的RGB-D语义分割工作都集中在室内场景[7][9][10]，无法保证自动驾驶车辆所需的快速推理速度

另一方面，CNN的卓越能力是基于大量带注释的数据，尤其是语义分割任务[11]。**当前主流的自动驾驶数据集通常只假设场景中的某些固定类别的对象，而忽略了现实世界中意外的小障碍物等不可预见的危险。例如，Cityscapes[12]只将对象划分为19个类，而没有定义任何意外的类。多源训练已被证明可以有效地提高可识别语义，而无需重新标记数据集[13]**。然而，以前的多源培训框架只考虑了RGB数据标签层次结构中的异质性，没有机会利用来自不同来源的补充深度信息

**在本文中，我们提出了一个结合RGBD语义分割和障碍检测的框架。详细设计了一个用于RGB-D语义分割的实时融合网络RFNet。通过我们的多数据集训练策略，我们的框架能够将城市景观中的19个类别进行分类，并结合像素级意外小障碍检测（见图1）。大量实验表明了该框架在语义分割任务中的有效性和效率。我们工作的主要贡献有三个方面：•我们提出了RFNet，这是一种用于RGBD语义分割的实时融合网络，包含意外障碍物的检测，与城市景观数据集上的其他最先进方法相比，该网络具有更高的准确性和快速推理**

**•在提议的网络中有效提取深度互补特征，与单个RGB流架构相比，提高了准确性**

**•多数据集训练和体系结构中的深度流使网络能够非常有效地检测意外的小对象。**

**检测道路上意外的小型但潜在危险的障碍物是自动驾驶的一项重要任务，该课题一直是研究热点。通常，这些检测和定位一般障碍物的方法基于集成在自动驾驶汽车上的立体摄像头**

在这些方法中，大多数是基于通用几何准则。Stixel算法【27】用一组矩形垂直障碍物段表示障碍物，提供了3D场景的鲁棒表示。【28】和【29】等几何点聚类方法利用3D点之间的几何关系来检测和聚类障碍点

由于CNN在利用图像的视觉外观和语境方面的优势，它被应用于当代研究中。Ramos等人[8]提出了一个原则性的贝叶斯框架，用于融合卷积神经网络预测的语义分割和快速直接平面假设检验（FPHT）方法基于立体的检测结果。MergeNet[6]提出了一个多级训练程序，包括权重共享、从RGB-D输入中分离低层和高层特征的学习，以及学习融合获得的互补特征的细化阶段。但所有这些方法只能预测三大类：自由空间、障碍物和背景。为了满足自动驾驶的需求，我们需要一种更通用的方法，除了简单的道路/障碍物分离之外，还可以丰富可检测语义。在这项工作中，我们通过将意外障碍物检测合并到多源语义分割框架中来解决该问题，以提供统一的像素级场景理解。



# Unifying Terrain Awareness for the Visually Impaired through Real-Time Semantic Segmentation

 