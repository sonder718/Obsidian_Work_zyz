注意添加参考文献,学习他人的论文写法

# 核心功能

视障人士出行时得以选择安全且正确的行走路线,能够在语音的引导下走上盲道同时避开途中的障碍物,当遇到需穿过马路情景时能够引导用户在斑马线上通过马路,最终到达正确目的地。

本系统的核心技术难点在于感知,规划,决策,控制四个方面,其中重点与难点在于感知与规划.

# 感知

感知周围环境是系统最为重要的一环.对于盲人用户而言,环境中的两种信息是其最为关注的,一是环境中的盲道与人行道等道路标识线,二是前进方向上的障碍物.

## 感知道路标识线

本系统的核心宗旨是让盲人尽可能的走在安全的地方,而盲道与人行道作为相对更加安全的区域是我们所提倡前往的,因此对于盲道与人行道的感知不能够仅仅停留在检测的程度,还需要进行进一步的语义分割,提取延伸方向,与抽象化区域等工作.

最终需要感知到的信息包括如下:

1.  盲道与人行道的走向
    
2.  盲道与人行道的可行走区域(以一或多个闭包的形式表示)
    
3.  盲道起点与用户当前所处位置的角度与距离
    

此处主要使用相机获取的RGB图像信息.
进行规范化描述即为:
```
input:predicted_img

output:
blind_road_find=1//是否发现盲道
blind_road_distance=0.5m//盲道与使用者的距离
blind_road_angle=-30°//盲道在使用者的左边30度角位置
on_blind_road=1//使用者是否位于盲道上
blind_road_departure//使用者是否正在偏离盲道

sideways_find=1//是否发现人行道
sideways_distance=3.5m//人行道与使用者的距离
sideways_angle=30°//人行道在使用者的右边30度角位置
on_sideways=1//使用者是否位于人行道上
sideways_departure//使用者是否正在偏离人行道

```

### 语义分割

盲道与人行道作为特征较为明显的两类道路标识线,在输入图像较为清晰,背景环境简单,样本类型单一的情况下,利用二值化,canny边缘检测等传统图像处理算法能够取得较为良好的分割效果,且分割速度极快,但由于现实环境复杂多变,相机防抖的缺失,盲道种类繁多等原因,利用深度学习技术进行语义分割更加适宜本项目的需求.

bisenetv2,deeplabV3+

### 盲道与人行道走向获取

RANSAC

### 角度与距离获取

## 感知障碍物

在复杂现实场景中,盲人出行所面临有动态障碍物与静态障碍物两种障碍物类型.本项目中主要研究的是对静态障碍物的检测.

最终需要感知到的信息如下:
1.  障碍物的轮廓闭包
    
2.  障碍物与用户当前所处位置的角度与距离

进行规范化描述即为:
```
input:rgb_img,depth_img/ply格式点云,care_meter

output:
obs_all_find=1   //care_meter距离内是否发现障碍物

obs_front_find=1   //care_meter距离内行走正前方是否发现障碍物

closest_obs_distance=0.5m  //最近的前方可能相碰障碍物与使用者的距离

closest_obs_angle=-10°  //最近的前方可能相碰障碍物与使用者的角度

obs_list  //障碍物列表,按照距离进行排序 每个障碍物包括属性如下{distance:2m,angle:40,width:100cm,height=30cm}

```

[[代码阅读]]
利用深度图

点云对准
https://github.com/IntelRealSense/librealsense/blob/master/wrappers/python/examples/export_ply_example.py
导出为点云


# 规划

最终的目的是到达终点,大方向与小方向的融合问题,

## 可行走区域的分级

不可行走区域

可行走区域

建议行走区域

## 与尺度地图融合问题

安全性,便利性

一个情况:当盲道在旁边,目的地在对面时的应对

## 基于人工视场的避障方法

# 决策与控制

提示什么信息.如何提示